TITLE = "Alpaca-LoRA Playground"

ABSTRACT = """
Thanks to tolen, this simple application runs Alpaca-LoRA which is instruction fine-tuned version of [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) by Meta AI.

I am thankful to the [Jarvislabs.ai](https://jarvislabs.ai/) for providing free GPU instances. 
"""

BOTTOM_LINE = """
In order to process batch generation, the common parameters in LLaMA are fixed as below:
- temperature=0.90
- top_p=0.75
- num_beams=4
"""
